{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3fb14ca1-a007-43b2-b111-45b6889b3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fee015fc-4d3d-4d92-8f9a-ce69b1a7e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la distancia Euclidiana\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "# Implementación manual de KNN para encontrar los k vecinos más cercanos\n",
    "def find_k_nearest_neighbors(X_train, x_test, k):\n",
    "    distances = []\n",
    "    for i, x_train in enumerate(X_train):\n",
    "        distance = euclidean_distance(x_train, x_test)\n",
    "        distances.append((distance, i))  # Guardamos la distancia y el índice\n",
    "    distances.sort(key=lambda x: x[0])  # Ordenar por distancia\n",
    "    return [idx for _, idx in distances[:k]]  # Retornar los índices de los k vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "08dffd6e-75b1-41e2-a8a0-7c3cd300285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de SMOTE\n",
    "def smote(X, y, k_sm=5):\n",
    "    counter = Counter(y)\n",
    "    max_count = max(counter.values())\n",
    "    minority_class = min(counter, key=counter.get)\n",
    "    majority_class = max(counter, key=counter.get)\n",
    "    \n",
    "    X_minority = X[y == minority_class]\n",
    "    num_samples_to_generate = max_count - counter[minority_class]\n",
    "    \n",
    "    synthetic_samples = []\n",
    "    \n",
    "    # Generar muestras sintéticas\n",
    "    for _ in range(num_samples_to_generate):\n",
    "        # Seleccionar una muestra aleatoria de la clase minoritaria\n",
    "        idx = np.random.randint(0, X_minority.shape[0])\n",
    "        point = X_minority[idx]\n",
    "        \n",
    "        # Encontrar los k vecinos más cercanos\n",
    "        neighbors_idx = find_k_nearest_neighbors(X_minority, point, k)\n",
    "        \n",
    "        # Seleccionar un vecino aleatorio\n",
    "        neighbor_idx = np.random.choice(neighbors_idx)\n",
    "        neighbor = X_minority[neighbor_idx]\n",
    "        \n",
    "        # Interpolación aleatoria entre la muestra y su vecino\n",
    "        alpha = np.random.rand()\n",
    "        synthetic_sample = point + alpha * (neighbor - point)\n",
    "        synthetic_samples.append(synthetic_sample)\n",
    "    \n",
    "    # Convertir las muestras sintéticas en un array numpy\n",
    "    X_synthetic = np.array(synthetic_samples)\n",
    "    y_synthetic = np.full(X_synthetic.shape[0], minority_class)\n",
    "    \n",
    "    # Combinar los datos originales con los sintéticos\n",
    "    X_sm = np.vstack([X, X_synthetic])\n",
    "    y_sm = np.hstack([y, y_synthetic])\n",
    "    \n",
    "    return X_sm, y_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2e199531-3c8b-4d29-86bc-82594d2f5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_nn_classifier(X_train, y_train, X_test):\n",
    "    def euclidean_distance(x1, x2):\n",
    "        return sum((xi - yi) ** 2 for xi, yi in zip(x1, x2)) ** 0.5\n",
    "\n",
    "    y_pred = [] # Lista para almacenar las predicciones\n",
    "\n",
    "    # Predicción para cada muestra en el conjunto de prueba\n",
    "    for x_test in X_test:\n",
    "        # Inicializar la menor distancia como infinita y sin etiqueta\n",
    "        min_distance = float('inf')\n",
    "        closest_label = None\n",
    "\n",
    "        # Buscar el vecino más cercano\n",
    "        for i, x_train in enumerate(X_train):\n",
    "            distance = euclidean_distance(x_test, x_train)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_label = y_train[i]\n",
    "\n",
    "        y_pred.append(closest_label) # Guardar la predicción\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0cf892a6-81d1-4fe5-adf7-07e142a2bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el clasificador KNN\n",
    "def knn_classifier(X_train, y_train, X_test, k):\n",
    "    def euclidean_distance(x1, x2):\n",
    "        return sum((xi - yi) ** 2 for xi, yi in zip(x1, x2)) ** 0.5\n",
    "\n",
    "    y_pred = []  # Lista para almacenar las predicciones\n",
    "\n",
    "    for x_test in X_test:\n",
    "        # Calcular la distancia de x_test a todos los puntos en X_train\n",
    "        distances = [(euclidean_distance(x_test, x_train), label) for x_train, label in zip(X_train, y_train)]\n",
    "        # Ordenar por distancia y seleccionar los k vecinos más cercanos\n",
    "        k_nearest_neighbors = sorted(distances, key=lambda x: x[0])[:k]\n",
    "        # Obtener las etiquetas de los k vecinos y elegir la más común\n",
    "        k_nearest_labels = [label for _, label in k_nearest_neighbors]\n",
    "        most_common_label = Counter(k_nearest_labels).most_common(1)[0][0]\n",
    "        y_pred.append(most_common_label)\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2f80ee73-8f19-426f-8231-651f1c8510cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hold_out_validation(data,k,r=0.3):\n",
    "    # Separar características y etiquetas\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    # Verificar y limpiar etiquetas\n",
    "    valid_indices = ~pd.isnull(y)\n",
    "    X = X[valid_indices]\n",
    "    y = y[valid_indices]\n",
    "    y = y.astype(int)\n",
    "\n",
    "    # Determinar el tamaño de prueba y mezclar índices\n",
    "    n = len(X)\n",
    "    test_size = int(n * r)\n",
    "    indices = list(range(n))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    # Crear subconjuntos de entrenamiento y prueba\n",
    "    train_indices = np.array(indices[:n - test_size])\n",
    "    test_indices = np.array(indices[n - test_size:])\n",
    "    X_train, y_train = X[train_indices], y[train_indices]\n",
    "    X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "    counter = Counter(y_train)\n",
    "    print('Before', counter)\n",
    "     # Predicción con el clasificador de knn y 1nn\n",
    "    y_pred_knn= knn_classifier(X_train, y_train, X_test, k=k)\n",
    "    y_pred_1nn = one_nn_classifier(X_train, y_train, X_test)\n",
    "\n",
    "    # Oversampling the train dataset using SMOTE\n",
    "    X_train_sm, y_train_sm = smote(X_train, y_train,k_sm=5)\n",
    "\n",
    "    counter = Counter(y_train_sm)\n",
    "    print('After SMOTE:', counter)\n",
    "\n",
    "    # Predicción con el clasificador de knn y 1nn\n",
    "    y_pred_knn_sm= knn_classifier(X_train_sm, y_train_sm, X_test, k=k)\n",
    "    y_pred_1nn_sm= one_nn_classifier(X_train_sm, y_train_sm, X_test)\n",
    "\n",
    "    #if y_train == y_train_sm:\n",
    "    #   print(\" Hold out SON IGUALES\")\n",
    "\n",
    "    return y_test, y_pred_knn, y_pred_1nn, y_pred_knn_sm, y_pred_1nn_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4b0a6c4e-bace-4984-9088-372c9ce3fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_validation(data,k,num_folds=10):\n",
    "    # Separar características y etiquetas\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    # Dividir los datos en K partes (folds)\n",
    "    folds = np.array_split(data, num_folds)\n",
    "\n",
    "    # Listas para acumular los resultados \n",
    "    y_tests = []\n",
    "    y_preds_1nn = []\n",
    "    y_preds_knn = []\n",
    "    y_preds_1nn_sm = []\n",
    "    y_preds_knn_sm = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        # Crear conjuntos de prueba y entrenamiento\n",
    "        test_data = folds[i]\n",
    "        train_data = pd.concat([folds[j] for j in range(num_folds) if j != i])\n",
    "\n",
    "        X_train = train_data.iloc[:, :-1].values\n",
    "        y_train = train_data.iloc[:, -1].values\n",
    "        X_test = test_data.iloc[:, :-1].values\n",
    "        y_test = test_data.iloc[:, -1].values\n",
    "\n",
    "        counter = Counter(y_train)\n",
    "        print('Before', counter)\n",
    "        \n",
    "        # Predicciones usando el clasificador de knn y 1nn\n",
    "        y_pred_knn = knn_classifier(X_train, y_train, X_test,k=k)\n",
    "        y_pred_1nn = one_nn_classifier(X_train, y_train, X_test)\n",
    "\n",
    "        \n",
    "        # oversampling the train dataset using SMOTE\n",
    "        X_train_sm, y_train_sm = smote(X_train, y_train,k_sm=5)\n",
    "        \n",
    "        counter = Counter(y_train_sm)\n",
    "        print('After', counter)\n",
    "        \n",
    "        # Predicciones usando el clasificador de knn y 1nn\n",
    "        y_pred_knn_sm = knn_classifier(X_train_sm, y_train_sm, X_test,k=k)\n",
    "        y_pred_1nn_sm = one_nn_classifier(X_train_sm, y_train_sm, X_test)\n",
    "        \n",
    "        # Acumular los resultados de prueba y predicción\n",
    "        y_tests.extend(y_test)\n",
    "        y_preds_knn.extend(y_pred_knn)\n",
    "        y_preds_1nn.extend(y_pred_1nn)\n",
    "        y_preds_knn_sm.extend(y_pred_knn_sm)\n",
    "        y_preds_1nn_sm.extend(y_pred_1nn_sm)\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    return y_tests, y_preds_knn, y_preds_1nn, y_preds_knn_sm, y_preds_1nn_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4ebdb6a7-43f5-4d04-806b-9fa83bb41d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Matriz de Confusión:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c0de4f4b-9f75-48ee-a9e3-bea2f5894abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************************\n",
      "\n",
      "--- Validación en glass.csv ---\n",
      "Before Counter({2: 55, 1: 49, 7: 19, 5: 11, 3: 10, 6: 6})\n",
      "After SMOTE: Counter({2: 55, 6: 55, 1: 49, 7: 19, 5: 11, 3: 10})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (150,) (199,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Validación en \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Hold-Out 70/30 Estratificado\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m y_test, y_preds_knn, y_preds_1nn, y_preds_knn_sm, y_preds_1nn_sm \u001b[38;5;241m=\u001b[39m \u001b[43mhold_out_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---- KNN ----\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mHold-Out (70/30 Estratificado):  (SIN SMOTE)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m evaluate_performance(y_test, y_preds_knn)\n",
      "Cell \u001b[1;32mIn[135], line 40\u001b[0m, in \u001b[0;36mhold_out_validation\u001b[1;34m(data, k, r)\u001b[0m\n\u001b[0;32m     37\u001b[0m y_pred_knn_sm\u001b[38;5;241m=\u001b[39m knn_classifier(X_train_sm, y_train_sm, X_test, k\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m     38\u001b[0m y_pred_1nn_sm\u001b[38;5;241m=\u001b[39m one_nn_classifier(X_train_sm, y_train_sm, X_test)\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train_sm\u001b[49m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Hold out SON IGUALES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_test, y_pred_knn, y_pred_1nn, y_pred_knn_sm, y_pred_1nn_sm\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (150,) (199,) "
     ]
    }
   ],
   "source": [
    "# Cargar y validar cada dataset\n",
    "datasets = ['glass.csv']\n",
    "k = 1\n",
    "\n",
    "for dataset in datasets:\n",
    "    data = pd.read_csv(dataset)\n",
    "\n",
    "    print(f\"*******************************************************************************************\")\n",
    "    print(f\"\\n--- Validación en {dataset} ---\")\n",
    "    \n",
    "    # Hold-Out 70/30 Estratificado\n",
    "    y_test, y_preds_knn, y_preds_1nn, y_preds_knn_sm, y_preds_1nn_sm = hold_out_validation(data,k)\n",
    "    print(\"\\n---- KNN ----\\nHold-Out (70/30 Estratificado):  (SIN SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_knn)\n",
    "    print(\"\\n---- 1NN ----\\nHold-Out (70/30 Estratificado): (SIN SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_1nn)\n",
    "    print(\"\\n---- KNN ----\\nHold-Out (70/30 Estratificado):  (SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_knn_sm)\n",
    "    print(\"\\n---- 1NN ----\\nHold-Out (70/30 Estratificado): (SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_1nn_sm)\n",
    "    # Comparar que no sean las mismas listas \n",
    "    if y_preds_knn == y_preds_knn_sm: \n",
    "        print(\"Son iguales\")\n",
    "    \n",
    "    # 10-Fold Cross-Validation Estratificado\n",
    "    y_test, y_preds_knn, y_preds_1nn, y_preds_knn_sm, y_preds_1nn_sm = k_fold_validation(data,k)\n",
    "    print(\"\\n---- KNN ----\\n10-Fold Cross-Validation Estratificado: (SIN SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_knn)\n",
    "    print(\"\\n---- 1NN ----\\n10-Fold Cross-Validation Estratificado: (SIN SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_1nn)\n",
    "    print(\"\\n---- KNN ----\\n10-Fold Cross-Validation Estratificado: (SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_knn_sm)\n",
    "    print(\"\\n---- 1NN ----\\n10-Fold Cross-Validation Estratificado: (SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_1nn_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f6922-4fde-4382-b292-f367774f0dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e4c07b-9f45-4397-b6ef-fbf2facecf37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
